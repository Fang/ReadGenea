\nonstopmode{}
\documentclass[a4paper]{book}
\usepackage[times,inconsolata,hyper]{Rd}
\usepackage{makeidx}
\usepackage[utf8,latin1]{inputenc}
% \usepackage{graphicx} % @USE GRAPHICX@
\makeindex{}
\begin{document}
\chapter*{}
\begin{center}
{\textbf{\huge Package `ReadGenea'}}
\par\bigskip{\large \today}
\end{center}
\begin{description}
\raggedright{}
\item[Type]\AsIs{Package}
\item[Title]\AsIs{Package For Reading Binary files}
\item[Version]\AsIs{2.5}
\item[Date]\AsIs{23/05/2012}
\item[Author]\AsIs{ActivInsights Ltd. }\email{joss.langford@activinsights.co.uk}\AsIs{}
\item[Maintainer]\AsIs{ActivInsights Ltd. }\email{joss.langford@activinsights.co.uk}\AsIs{}
\item[Description]\AsIs{Functions and analytics for Genea accelerometer data into R objects}
\item[License]\AsIs{GPL}
\item[LazyLoad]\AsIs{yes}
\item[ByteCompile]\AsIs{yes}
\item[Depends]\AsIs{bitops, chron}
\item[Suggests]\AsIs{mmap, MASS}
\end{description}
\Rdcontents{\R{} topics documented:}
\inputencoding{utf8}
\HeaderA{ReadGenea-package}{ReadGenea: a package to process binary accelerometer output files.}{ReadGenea.Rdash.package}
\aliasA{ReadGenea}{ReadGenea-package}{ReadGenea}
\keyword{package}{ReadGenea-package}
%
\begin{Description}\relax
This is a package to process binary output files from the Genea accelerometer data.  The main function is:\\{}\\{}

read.bin\\{}
\end{Description}
%
\begin{Details}\relax

\Tabular{ll}{
Package: & ReadGenea\\{}
Type: & Package\\{}
Version: & 2.0-1\\{}
Date: & 12/10/2011\\{}
License: & GPL\\{}
LazyLoad: & yes\\{}
}

\end{Details}
%
\begin{Author}\relax
ActivInsights Ltd. <joss.langford@activinsights.co.uk>
\end{Author}
\inputencoding{utf8}
\HeaderA{epoch.apply}{Compute epochal summary statistics.}{epoch.apply}
\aliasA{epoch.autocor}{epoch.apply}{epoch.autocor}
\aliasA{epoch.mad}{epoch.apply}{epoch.mad}
\aliasA{epoch.mean}{epoch.apply}{epoch.mean}
\aliasA{epoch.median}{epoch.apply}{epoch.median}
\aliasA{epoch.quantile}{epoch.apply}{epoch.quantile}
\aliasA{epoch.sd}{epoch.apply}{epoch.sd}
\aliasA{svm}{epoch.apply}{svm}
\keyword{manip}{epoch.apply}
%
\begin{Description}\relax
Computes epochal summary statistics for an "AccData" object, matrix, or vector, and collates into a matrix or vector.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
epoch.apply(obj, epoch.size=10, FUN, incl.date = FALSE)

epoch.mean(obj, epoch.size=10, incl.date = FALSE, sqrt )
epoch.sd(obj, epoch.size=10, incl.date = FALSE, sqrt )
epoch.median(obj, epoch.size=10, incl.date = FALSE, sqrt )
epoch.mad(obj, epoch.size=10, incl.date = FALSE, sqrt )
epoch.autocor(obj, epoch.size=10, lag = 1, type = 
    c("correlation", "covariance", "partial"), incl.date = FALSE, sqrt)
epoch.quantile(obj, epoch.size = 10, 
    quantiles= c(0.1, 0.25, 0.5, 0.75, 0.9), incl.date = FALSE, sqrt )

svm(obj, sqrt )
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj}] The object to compute statistics for. Can be an "AccData" object, a matrix, or a vector.
\item[\code{epoch.size}] Numeric giving intervals to consider and aggregate. For "AccData" \code{obj} taken as seconds. Otherwise, considered as rows, or as individual readings.
\item[\code{incl.date}] logical. If TRUE, include a column of times or original indices with the results.
\item[\code{FUN}] A function to be applied to each epoch.
\item[\code{sqrt}] logical. If TRUE, the square rooted svm will be used in computations instead.
\item[\code{lag}] Autocorrelation lag to compute.
\item[\code{type}] Type of autocorrelation, as used in \code{\LinkA{acf}{acf}}.
\item[\code{quantiles}] Sample quantiles of SVM to compute.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
These functions compute epochal summary statistics for "AccData" objects, matrices and vectors.

\code{epoch.apply} is the general function - according to the size of \code{epoch.size}, it splits up the obj into collections of consecutive rows, each with the same size. These are then successively supplied to \code{FUN} as its first argument. If the result of FUN is a single value, then the results are concatenated into a vector output. Otherwise, an array is formed with each row corresponding to a single epochal group. For AccData, the sampling frequency of the dataset is used to interpret the epoch size in seconds. Otherwise, the raw record indices are used. If incl.date is set, the original timestamp vector of the data, or the original indices, are downsampled and included as the first column of the output.

The remaining functions are wrappers that compute various commonly useful statistics -- in particular, applied to "AccData" objects and arrays, they by default compute the epochal SVM mean, standard deviation, median, median absolute deviation, and autocorrelation, and sample quantiles respectively. (Arrays are treated as each column representing the x, y, and z components respectively.) Applied to vector input, processing will occur without the SVM calculation. This behaviour may be overridden by the sqrt setting, which will force the function to use the squared (default for arrays and "AccData") or original unit (default for vectors) values in the statistical analysis.

\code{svm} acts identically to 'epoch.mean', with the epoch set to the sampling period. In other words, it computes the instantaneous sum of vector magnitudes of the acceleration at each record point. The function takes "AccData", array and vector input. Note that if provided with an array with 4 or more columns, columns 2 to 4 are used -- the first column is regard as a timestamp and hence ignored.
\end{Details}
%
\begin{Value}
A vector or array giving the computed epochal summaries. With \code{incl.date = TRUE}, the result is given as a data.frame suitable for plotting.
\end{Value}
%
\begin{SeeAlso}\relax
\code{\LinkA{plot.AccData}{plot.AccData}}, \code{\LinkA{summary.AccData}{summary.AccData}}, \code{\LinkA{aggregate}{aggregate}}, \code{\LinkA{acf}{acf}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

dat <- read.bin(system.file("binfile/TESTfile.bin", package = "ReadGenea")[1]
    , calibrate = TRUE)

#look for the epochs that exceed a certain threshold 50% of the time
plot(epoch.apply( dat, epoch.size = 3 , 
    FUN = function(t) mean(abs(svm(t) -1)>0.2)> 0.5 ), type = "l")

plot(dat[,1], svm(dat), log = "y", pch = ".")
lines(epoch.mean(dat, incl.date = TRUE), lwd = 2)
lines(epoch.mean(dat, epoch.size = 30, incl.date = TRUE), col = 2, lwd = 2)
#this should give all the same results, but by a different way
lines(epoch.apply(dat, epoch.size = 30, 
    FUN = function(A) mean(svm(A, FALSE)), incl.date = TRUE), col = 3)
epsize = 30; lines(epoch.apply(dat, epoch.size = epsize, 
    FUN = function(t) median(t[,1])), epoch.apply(dat, epoch.size = epsize, 
    FUN = function(A) mean(svm(A, FALSE))), col = 4)
#note this is different
lines(epoch.apply(dat, epoch.size = epsize, 
    FUN = function(t) median(t[,1])),epoch.apply(dat, epoch.size = epsize, 
    FUN = function(A) mean(svm(A, sqrt = TRUE)))^2, col = 5)

#plot some statistics
par(mfrow = c(5,1), mar = c(1,4.5,1,1))
plot(epoch.sd(dat), type="l")
plot(epoch.median(dat), type= "l")
plot(epoch.mad(dat), type= "l")
plot(epoch.autocor(dat), type= "l")
tmp = epoch.quantile(dat, quantiles= c(0.1, 0.25, 0.5, 0.75, 0.9)); matplot(tmp, type = "l")


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{header.info}{Get header info from Genea output (.bin) file}{header.info}
\keyword{manip}{header.info}
%
\begin{Description}\relax
Function to extract relevant header fields and values from a file.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
header.info(binfile, more=TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{binfile}] The file from which to extract the header
\item[\code{more}] logical. If TRUE, extract additional data from file useful for calibration and data reading.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The function extracts useful information from a .bin file, such as information about the Genea device used to produce the output, and characteristics of the subject who wore the device. The function also accepts data that has been compressed in `gzip', `bzip2' or `xz' formats. See \code{file}.
With \code{more} set to TRUE, additional data is extracted, mainly for internal use in \code{read.bin}.
\end{Details}
%
\begin{Value}
A \code{data.frame} with extracted header information, each row a particular header field with its value. 
If \code{more} is TRUE, an attribute "calibration" is attached to the object, consisting of a list with measurement offsets, sampling frequency estimates, start times and time zones, data position offsets, and if mmap is detected, byte locations and increments for mmap reading.
\end{Value}
%
\begin{Section}{Warning}
This function is specific to header structure in Geneactiv output files. By design, it should be compatible with all firmware and software versions to date (as of version of current release). If order or field names are changed in future .bin files, this function may have to be updated appropriately.
The function works by looking for appropriate section headings in the .bin files.
\end{Section}
%
\begin{SeeAlso}\relax
\code{\LinkA{read.bin}{read.bin}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

fileheader <- header.info(system.file("binfile/TESTfile.bin", package = "ReadGenea")[1], more = TRUE)
print(fileheader)
attr(fileheader, "calibration")
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{read.bin}{File processing function for binary files.}{read.bin}
\keyword{manip}{read.bin}
%
\begin{Description}\relax
A function to process binary accelerometer files and convert the information into R objects.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
read.bin(binfile, outfile = NULL, start = NULL, end = NULL, 
    verbose = TRUE, do.temp = TRUE,do.volt = TRUE, calibrate = TRUE, downsample = NULL, blocksize , virtual = FALSE, mmap.load = (.Machine$sizeof.pointer >= 8), pagerefs = TRUE, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{binfile}] 
A filename of a file to process.

\item[\code{outfile}] 
An optional filename specifying where to save the processed data object.

\item[\code{start}] Either:
A representation of when in the file to begin processing, see Details.

\item[\code{end}] Either:
A representation of when in the file to end processing, see Details.

\item[\code{verbose}] 
A boolean variable indicating whether some information should be printed during processing should be printed.

\item[\code{do.temp}] 
A boolean variable indicating whether the temperature signal should be extracted.

\item[\code{do.volt}] 
A boolean variable indicating whether the voltage signal should be extracted.

\item[\code{calibrate}] 
A boolean variable indicating whether the raw accelerometer values and the light variable should be calibrated according to the calibration data in the headers.

\item[\code{downsample}] 
A variable indicating the type of downsampling to apply to the data as it is loaded. Can take values:\\{}\\{}
\code{NULL}: (Default) No downsampling\\{}
Single numeric: Reads every \code{downsample}-th value, starting from the first.\\{}
Length two numeric vector: Reads every \code{downsample[1]}-th value, starting from the \code{downsample[2]}-th.\\{}\\{}

Non-integer, or non-divisor of 300 downsampling factors are allowed, but will lead to imprecise frequency calculations, leap seconds being introduced, and generally potential problems with other methods. Use with care.


\item[\code{blocksize}] 
Integer value giving maximum number of data pages to read in each pass. Defaults to 10000 for larger data files. Sufficiently small sizes will split very large data files to read chunk by chunk, reducing memory requirements for the read.bin function (without affecting the final object), but conversely possibly increasing processing time. Can be set to Inf for no splitting.


\item[\code{virtual}] 
logical. If set TRUE, do not do any actual data reading. Instead construct a VirtualAccData object containing header information to allow use with \code{\LinkA{get.intervals}{get.intervals}}.


\item[\code{mmap.load}] 
logical. If TRUE (Default on 64bit R), use the \code{\LinkA{mmap}{mmap}} package to process the binfile.


\item[\code{pagerefs}] 
A variable that can take two forms, and is considered only for \code{mmap.load = TRUE}\\{}\\{}
NULL or FALSE, in which case pagerefs are dynamically calculated for each record. (Default) \\{}
A vector giving sorted byte offsets for each record for mmap reading of data files.\\{}
TRUE, in which case a full page reference table is computed before any processing occurs.\\{}\\{}

Computing pagerefs takes a little time and so is a little slower. However, it is safer than dynamic computations in the case of missing pages and high temperature variations. Further, once page references are calculated, future reads are much faster, so long as the previously computed references are supplied.



\item[\code{...}] Any other optional arguments can be supplied that affect manual calibration and data processing.  These are: \\{}\\{}

\code{gain}: a vector of 3 values for manual gain calibration of the raw (x,y,z) axes.  If \code{gain=NULL}, the gain calibration values are taken from within the output file itself.\\{}

\code{offset}: a vector of 3 value for manual offset calibration of the raw (x,y,z) axes.  If \code{offset=NULL}, the offset calibration values are taken from within the output file itself.\\{}

\code{luxv}: a value for manual lux calibration of the light meter.  If \code{luxv=NULL}, the lux calibration value is taken from within the output file itself.\\{}

\code{voltv}: a value for manual volts calibration of the light meter.  If \code{voltv=NULL}, the volts calibration value is taken from within the output file itself.\\{}

\code{warn}: if set to true, give a warning if input file is large, and require user confirmation.


\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The read.bin package reads in binary files compatible with the GeneActiv line of Accelerometers, for further processing by the other functions in this package. Most of the default options are those required in the most common cases, though users are advised to consider setting start and end to smaller intervals and/or choosing some level of downsampling when working with data files of longer than 24 hours in length.

The function reads in the desired analysis time window specified by \code{start} and \code{end}. For convenience, a variety of time window formats are accepted:

Large integers are read as page numbers in the dataset. Page numbers larger than that which is available in the file itself are constrained to what is available. Note that the first page is page 1.

Small values (between 0 and 1) are taken as proportions of the data. For example, `start = 0.5` would specify that reading should begin at the midpoint of the data.

Strings are interpreted as dates and times using \code{\LinkA{parse.time}{parse.time}}. In particular, times specified as "HH:MM" or "HH:MM:SS" are taken as the earliest time interval containing these times in the file. Strings with an integer prepended, using a space seperator, as interpreted as that time after the appropriate number of midnights have passed. In these, the time is interpreted in the same time zone as the data recording itself.

Actual data reading proceeds by two methods, depending on whether \code{mmap} is true or false. With \code{mmap = FALSE}, data is read in line by line using \code{readLine} until blocksize is filled, and then processed. With \code{mmap = TRUE}, the \code{\LinkA{mmap}{mmap}} package is used to map the entire data file into an address file, byte locations are calculated (depending on the setting of \code{pagerefs}), \code{blocksize} chunks of data are loaded, and then processed as raw vectors. 

There are advantages and disadvantages to both methods: the mmap method is usually much faster, especially when we are only loading the final parts of the data. ReadLine will have to process the entire file in such a case. On the other hand, mmap requires a large amount of memory address space, and so can fail in 32 bit systems. Finally, reading of compressed bin files can only be done with the readLine method. Generally, if mmap reading fails, the function will attempt to catch the failure, and reprocess the file with the readLine method, giving a warning.

Once data is loaded, calibration is then either performed using values from the binary file, or using manually inputted values (using the \code{gain}, \code{offset},\code{luxv} and \code{voltv} arguments).

\end{Details}
%
\begin{Value}
With \code{virtual = FALSE}, an "AccData" S3 object with 9 components:
\begin{ldescription}
\item[\code{data.out}] A 6 or 7 column matrix of the processed pages, the rows of which are the processed observations in order of processed pages.  The matrix has columns (timestamp,x-axis,y-axis,z-axis,light,button) or (timestamp,x-axis,y-axis,z-axis,light,button,temperature) if \code{do.temp=TRUE}. The timestamp is stored as seconds since 1 Jan 1970, in the timezone that the data is recorded in.
\item[\code{page.timestamps}] The timestamps as POSIXct representations (as opposed to those within the \code{data.out} array.)
\item[\code{freq}] The effective sampling frequency (in Hz).
\item[\code{filename}] The file name of the bin file.
\item[\code{page.numbers}] The pages that were loaded.
\item[\code{call}] The function call that the object was created with.
\item[\code{volt}] The battery voltage associated with each loaded page, if \code{do.volt} is TRUE.
\item[\code{pagerefs}] The page byte offsets that were computed.
\item[\code{header}] File header output, as given by \code{\LinkA{header.info}{header.info}}.

\end{ldescription}
Various processing methods are implemented so that \code{AccData} objects can be treated as an ordinary matrix in many cases. See \code{\LinkA{print.AccData}{print.AccData}} for info.

With \code{virtual = TRUE}, a "VirtAccData" S3 object with page.timestamps, freq, filename, page.numbers, call, pagerefs, header as in the earlier case, but also,
\begin{ldescription}
\item[\code{data.out}] A vector containing the timestamps of each page, using local seconds since 1970.
\item[\code{nobs}] Number of observations per page, after downsampling.
\end{ldescription}
\end{Value}
%
\begin{Section}{Warning}
Reading in an entire .bin file will take a long time if the file contains a lot of datasets. Reading in such files without downsampling can use up all available memory. See \code{\LinkA{memory.limit}{memory.limit}}.

This function is specific to header structure in Geneactiv output files. By design, it should be compatible with all firmware and software versions to date (as of version of current release). If order or field names are changed in future .bin files, this function may have to be updated appropriately.
\end{Section}
%
\begin{SeeAlso}\relax
\code{\LinkA{header.info}{header.info}}, \code{\LinkA{print.AccData}{print.AccData}}, \code{\LinkA{get.intervals}{get.intervals}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

binfile  = system.file("binfile/TESTfile.bin", package = "ReadGenea")[1]

#Read in the entire file, calibrated
procfile<-read.bin(binfile)
print(procfile)
procfile$data.out[1:5,]

#Uncalibrated, mmap off
procfile2<-read.bin(binfile, calibrate = FALSE)
procfile2$data.out[1:5,]

#Read in again, reusing already computed mmap pagerefs
procfile3<-read.bin(binfile, pagerefs = procfile2$pagerefs )

#Downsample by a factor of 10
procfilelo<-read.bin(binfile, downsample = 10)
print(procfilelo)
object.size(procfilelo) / object.size(procfile)

#Read in a 1 minute interval
procfileshort <- read.bin(binfile, start = "16:50", end = "16:51")
print(procfileshort)

##NOT RUN: Read, and save as a R workspace
#read.bin(binfile, outfile="tmp.Rdata")
#print(load("tmp.Rdata"))
#print(processedfile)


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{reformat.time}{Reformats a character time representation to a POSIXct object. }{reformat.time}
\keyword{manip}{reformat.time}
%
\begin{Description}\relax
A function to reformat a time representation to a POSIXct object.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
reformat.time(t,format="julian")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{t}] A character string representation of a date-time expression, for example colon-separated.
\item[\code{format}] A character string indicating which date-time representation to output.  Can be either \code{POSIX}, \code{julian} or \code{seconds}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The function separates individual components in a date-time representation, adding enough components if necessary so that the representation has seconds.
Note that the representation should either be colon-separated, or as a space-separated date-time string of the form: Y-m-d h:m.  Once this is done the time
is converted to the required format: \code{POSIX} is the usual R POSIXct format; \code{julian} is the julian date-time representation, modified so that the origin is midnight, 1st January, 2000; \code{seconds} is the number of seconds (including subseconds) since 1st January, 2000.  Note that this is similar to the usual Unix \code{date '+\%s'} function, which is the number of seconds since 1st January, 1970.
\end{Details}
%
\begin{Value}
A converted date-time string in the specified format.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}

#reformat.time("2011:02:11:12:34:02","julian")

#reformat.time("2010-07-19 13:04:01","POSIX")

\end{ExampleCode}
\end{Examples}
\printindex{}
\end{document}
