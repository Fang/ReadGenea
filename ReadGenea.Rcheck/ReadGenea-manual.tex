\nonstopmode{}
\documentclass[a4paper]{book}
\usepackage[times,inconsolata,hyper]{Rd}
\usepackage{makeidx}
\usepackage[utf8,latin1]{inputenc}
% \usepackage{graphicx} % @USE GRAPHICX@
\makeindex{}
\begin{document}
\chapter*{}
\begin{center}
{\textbf{\huge Package `ReadGenea'}}
\par\bigskip{\large \today}
\end{center}
\begin{description}
\raggedright{}
\item[Type]\AsIs{Package}
\item[Title]\AsIs{Package For Reading Binary files}
\item[Version]\AsIs{2.5}
\item[Date]\AsIs{23/05/2012}
\item[Author]\AsIs{ActivInsights Ltd. }\email{joss.langford@activinsights.co.uk}\AsIs{}
\item[Maintainer]\AsIs{ActivInsights Ltd. }\email{joss.langford@activinsights.co.uk}\AsIs{}
\item[Description]\AsIs{Functions and analytics for Genea accelerometer data into R objects}
\item[License]\AsIs{GPL}
\item[LazyLoad]\AsIs{yes}
\item[ByteCompile]\AsIs{yes}
\item[Depends]\AsIs{bitops}
\item[Suggests]\AsIs{mmap, MASS}
\end{description}
\Rdcontents{\R{} topics documented:}
\inputencoding{utf8}
\HeaderA{ReadGenea-package}{ReadGenea: a package to process binary accelerometer output files.}{ReadGenea.Rdash.package}
\aliasA{ReadGenea}{ReadGenea-package}{ReadGenea}
\keyword{package}{ReadGenea-package}
%
\begin{Description}\relax
This is a package to process binary output files from the Genea accelerometer data.  The main function is:\\{}\\{}

read.bin\\{}
\end{Description}
%
\begin{Details}\relax

\Tabular{ll}{
Package: & ReadGenea\\{}
Type: & Package\\{}
Version: & 2.0-1\\{}
Date: & 12/10/2011\\{}
License: & GPL\\{}
LazyLoad: & yes\\{}
}

\end{Details}
%
\begin{Author}\relax
ActivInsights Ltd. <joss.langford@activinsights.co.uk>
\end{Author}
\inputencoding{utf8}
\HeaderA{epoch.apply}{Compute epochal summary statistics.}{epoch.apply}
\aliasA{epoch.autocor}{epoch.apply}{epoch.autocor}
\aliasA{epoch.mad}{epoch.apply}{epoch.mad}
\aliasA{epoch.mean}{epoch.apply}{epoch.mean}
\aliasA{epoch.median}{epoch.apply}{epoch.median}
\aliasA{epoch.quantile}{epoch.apply}{epoch.quantile}
\aliasA{epoch.sd}{epoch.apply}{epoch.sd}
\aliasA{svm}{epoch.apply}{svm}
\keyword{manip}{epoch.apply}
%
\begin{Description}\relax
Computes epochal summary statistics for an "AccData" object, matrix, or vector, and collates into a matrix or vector.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
epoch.apply(obj, epoch.size=10, incl.date = FALSE, FUN)

epoch.mean(obj, epoch.size=10, incl.date = FALSE, sqrt )
epoch.sd(obj, epoch.size=10, incl.date = FALSE, sqrt )
epoch.median(obj, epoch.size=10, incl.date = FALSE, sqrt )
epoch.mad(obj, epoch.size=10, incl.date = FALSE, sqrt )
epoch.autocor(obj, epoch.size=10, lag = 1, type = 
    c("correlation", "covariance", "partial"), incl.date = FALSE, sqrt)
epoch.quantile(obj, epoch.size = 10, 
    quantiles= c(0.1, 0.25, 0.5, 0.75, 0.9), incl.date = FALSE, sqrt )

svm(obj, sqrt )
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj}] The object to compute statistics for. Can be an "AccData" object, a matrix, or a vector.
\item[\code{epoch.size}] Numeric giving intervals to consider and aggregate. For "AccData" \code{obj} taken as seconds. Otherwise, considered as rows, or as individual readings.
\item[\code{incl.date}] logical. If TRUE, include a column of times or original indices with the results.
\item[\code{FUN}] A function to be applied to each epoch.
\item[\code{sqrt}] logical. If TRUE, the square rooted svm will be used in computations instead.
\item[\code{lag}] Autocorrelation lag to compute.
\item[\code{type}] Type of autocorrelation, as used in \code{\LinkA{acf}{acf}}.
\item[\code{quantiles}] Sample quantiles of SVM to compute.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
These functions compute epochal summary statistics for "AccData" objects, matrices and vectors.

\code{epoch.apply} is the general function - according to the size of \code{epoch.size}, it splits up the obj into collections of consecutive rows, each with the same size. These are then successively supplied to \code{FUN} as its first argument. If the result of FUN is a single value, then the results are concatenated into a vector output. Otherwise, an array is formed with each row corresponding to a single epochal group. For AccData, the sampling frequency of the dataset is used to interpret the epoch size in seconds. Otherwise, the raw record indices are used. If incl.date is set, the original timestamp vector of the data, or the original indices, are downsampled and included as the first column of the output.

The remaining functions are wrappers that compute various commonly useful statistics -- in particular, applied to "AccData" objects and arrays, they by default compute the epochal SVM mean, standard deviation, median, median absolute deviation, and autocorrelation, and sample quantiles respectively. (Arrays are treated as each column representing the x, y, and z components respectively.) Applied to vector input, processing will occur without the SVM calculation. This behaviour may be overridden by the sqrt setting, which will force the function to use the squared (default for arrays and "AccData") or original unit (default for vectors) values in the statistical analysis.

\code{svm} acts identically to 'epoch.mean', with the epoch set to the sampling period. In other words, it computes the instantaneous sum of vector magnitudes of the acceleration at each record point. The function takes "AccData", array and vector input. Note that if provided with an array with 4 or more columns, columns 2 to 4 are used -- the first column is regard as a timestamp and hence ignored.
\end{Details}
%
\begin{Value}
A vector or array giving the computed epochal summaries. With \code{incl.date = TRUE}, the result is given as a data.frame suitable for plotting.
\end{Value}
%
\begin{SeeAlso}\relax
\code{\LinkA{plot.AccData}{plot.AccData}}, \code{\LinkA{summary.AccData}{summary.AccData}}, \code{\LinkA{aggregate}{aggregate}}, \code{\LinkA{acf}{acf}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

dat <- read.bin(system.file("binfile/TESTfile.bin", package = "ReadGenea")[1]
    , calibrate = TRUE)

#look for the epochs that exceed a certain threshold 50% of the time
plot(epoch.apply( dat, epoch.size = 3 , 
    FUN = function(t) mean(abs(svm(t) -1)>0.2)> 0.5 ), type = "l")

plot(dat[,1], svm(dat), log = "y", pch = ".")
lines(epoch.mean(dat, incl.date = TRUE), lwd = 2)
lines(epoch.mean(dat, epoch.size = 30, incl.date = TRUE), col = 2, lwd = 2)
#this should give all the same results, but by a different way
lines(epoch.apply(dat, epoch.size = 30, 
    FUN = function(A) mean(svm(A, FALSE)), incl.date = TRUE), col = 3)
epsize = 30; lines(epoch.apply(dat, epoch.size = epsize, 
    FUN = function(t) median(t[,1])), epoch.apply(dat, epoch.size = epsize, 
    FUN = function(A) mean(svm(A, FALSE))), col = 4)
#note this is different
lines(epoch.apply(dat, epoch.size = epsize, 
    FUN = function(t) median(t[,1])),epoch.apply(dat, epoch.size = epsize, 
    FUN = function(A) mean(svm(A, sqrt = TRUE)))^2, col = 5)

#plot some statistics
par(mfrow = c(5,1), mar = c(1,4.5,1,1))
plot(epoch.sd(dat), type="l")
plot(epoch.median(dat), type= "l")
plot(epoch.mad(dat), type= "l")
plot(epoch.autocor(dat), type= "l")
tmp = epoch.quantile(dat, quantiles= c(0.1, 0.25, 0.5, 0.75, 0.9)); matplot(tmp, type = "l")


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{header.info}{Get header info from Genea output (.bin) file}{header.info}
\keyword{manip}{header.info}
%
\begin{Description}\relax
Function to extract relevant header fields and values from a file.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
header.info(binfile, more=TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{binfile}] The file from which to extract the header
\item[\code{more}] logical. If TRUE, extract additional data from file useful for calibration and data reading.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The function extracts useful information from a .bin file, such as information about the Genea device used to produce the output, and characteristics of the subject who wore the device. The function also accepts data that has been compressed in `gzip', `bzip2' or `xz' formats. See \code{file}.
With \code{more} set to TRUE, additional data is extracted, mainly for internal use in \code{read.bin}.
\end{Details}
%
\begin{Value}
A \code{data.frame} with extracted header information, each row a particular header field with its value. 
If \code{more} is TRUE, an attribute "calibration" is attached to the object, consisting of a list with measurement offsets, sampling frequency estimates, start times and time zones, data position offsets, and if mmap is detected, byte locations and increments for mmap reading.
\end{Value}
%
\begin{Section}{Warning}
This function is specific to header structure in Geneactiv output files. By design, it should be compatible with all firmware and software versions to date (as of version of current release). If order or field names are changed in future .bin files, this function may have to be updated appropriately.
The function works by looking for appropriate section headings in the .bin files.
\end{Section}
%
\begin{SeeAlso}\relax
\code{\LinkA{read.bin}{read.bin}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

fileheader <- header.info(system.file("binfile/TESTfile.bin", package = "ReadGenea")[1], more = TRUE)
print(fileheader)
attr(fileheader, "calibration")
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{parse.time}{Parses a character time representation to another format. }{parse.time}
\keyword{manip}{parse.time}
%
\begin{Description}\relax
Converts a character vector in a variety of forms into either the raw second, second classed as POSIXct, or days since Unix epoch.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
parse.time(t="",format=c("seconds", "days", "POSIX"), tzone = 0, 
	start = NULL, startmidnight = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{t}] A character string representation of a date-time expression.
\item[\code{format}] A character string indicating which representation to output.  Can be either \code{seconds}, \code{days} or \code{POSIX}.
\item[\code{tzone}] The time zone the time is given in, expressed as an offset from UTC in hours.
\item[\code{start}] Earliest allowable time stamp in the data, as seconds since Unix epoch.
\item[\code{startmidnight}] Midnight of day '0' in the data, as seconds since Unix epoch.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The function processes character vectors of the form "DATE TIME" -- that is to say, a maximum of two terms separated by a space per value. 

"TIME" is given in 24 hour format, seperated by colons, in "hh:mm", "hh:mm:ss", "hh:mm:ss:ms" or "hh:mm:ss.ms" format. If ommitted, the time is taken to be 00:00:00.000.

"DATE" can be a date representation as "YYYY-MM-DD", "DD/MM/YY" or "DD/MM/YYYY" (noting the use of a colon or backslash seperator to distinguish between the two). Alternatively, with \code{start} and/or \code{startmidnight} supplied, an integer "NN" or string "DOW" corresponding to a day of the week can be used instead. Then, the function will find the first timestamp matching the correct "TIME", that falls NN midnights after \code{startmidnight} and is after \code{start}, or, in the latter case, the first timestamp after the day of \code{start} that matches the appropriate day of the week. If a blank "DATE" is supplied, the function will either use the UNIX epoch, or find the first match, corresponding to the case NN = 0.

Once this is done the time is converted to the required format: \code{POSIX} is the usual R POSIXct format; \code{days} is the julian days since UNIX epoch 1970-1-1; \code{seconds} is the number of seconds (including subseconds) since 1970-1-1. Note that for formats other than POSIX, the output is in the same timezone as \code{tzone}. POSIX stores the time internally as the time in UTC, and applies a format that gives this time local to the user.
\end{Details}
%
\begin{Value}
A converted date-time string in the specified format. In the case of "seconds", or "days", a numeric. For POSIX, a \code{\LinkA{POSIXct}{POSIXct}} object.
\end{Value}
%
\begin{SeeAlso}\relax
\code{\LinkA{convert.time}{convert.time}}, \code{\LinkA{get.intervals}{get.intervals}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

t1 = parse.time("2012-06-21 13:04:01"); print(t1)
parse.time("21/06/12 13:04:01") #gives the same result

parse.time(c("19/07/70", "20/07/70"), format = "days")
#results here will depend on your locale
parse.time(c("19/07/70", "20/07/70"), format = "POSIX", tzone = -4)

#one is the same day, one can only find a match the next day
parse.time("13:05", start = t1) - t1
parse.time("13:00", start = t1) - t1
#asking to wait 1 midnight means both times are considered as 
#times on the same, full day of data
parse.time(c("1 13:05", "1 13:00"), start = t1) - t1
#2012-06-21 is a Thursday, so this is equivalent
parse.time(c("Fri 13:05", "Fri 13:00"), start = t1) - t1
#Longer form days of the week are also understood. Note that 
#the first day does not get matched.
parse.time(c("Thursday 13:05", "Thursday 13:00"), start = t1) - t1

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{read.bin}{File processing function for binary files.}{read.bin}
\keyword{manip}{read.bin}
%
\begin{Description}\relax
A function to process binary accelerometer files and convert the information into R objects.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
read.bin(binfile, outfile = NULL, start = NULL, end = NULL, 
    verbose = TRUE, do.temp = TRUE,do.volt = TRUE, calibrate = TRUE, downsample = NULL, blocksize , virtual = FALSE, mmap.load = (.Machine$sizeof.pointer >= 8), pagerefs = TRUE, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{binfile}] 
A filename of a file to process.

\item[\code{outfile}] 
An optional filename specifying where to save the processed data object.

\item[\code{start}] Either:
A representation of when in the file to begin processing, see Details.

\item[\code{end}] Either:
A representation of when in the file to end processing, see Details.

\item[\code{verbose}] 
A boolean variable indicating whether some information should be printed during processing should be printed.

\item[\code{do.temp}] 
A boolean variable indicating whether the temperature signal should be extracted.

\item[\code{do.volt}] 
A boolean variable indicating whether the voltage signal should be extracted.

\item[\code{calibrate}] 
A boolean variable indicating whether the raw accelerometer values and the light variable should be calibrated according to the calibration data in the headers.

\item[\code{downsample}] 
A variable indicating the type of downsampling to apply to the data as it is loaded. Can take values:\\{}\\{}
\code{NULL}: (Default) No downsampling\\{}
Single numeric: Reads every \code{downsample}-th value, starting from the first.\\{}
Length two numeric vector: Reads every \code{downsample[1]}-th value, starting from the \code{downsample[2]}-th.\\{}\\{}

Non-integer, or non-divisor of 300 downsampling factors are allowed, but will lead to imprecise frequency calculations, leap seconds being introduced, and generally potential problems with other methods. Use with care.


\item[\code{blocksize}] 
Integer value giving maximum number of data pages to read in each pass. Defaults to 10000 for larger data files. Sufficiently small sizes will split very large data files to read chunk by chunk, reducing memory requirements for the read.bin function (without affecting the final object), but conversely possibly increasing processing time. Can be set to Inf for no splitting.


\item[\code{virtual}] 
logical. If set TRUE, do not do any actual data reading. Instead construct a VirtualAccData object containing header information to allow use with \code{\LinkA{get.intervals}{get.intervals}}.


\item[\code{mmap.load}] 
logical. If TRUE (Default on 64bit R), use the \code{\LinkA{mmap}{mmap}} package to process the binfile.


\item[\code{pagerefs}] 
A variable that can take two forms, and is considered only for \code{mmap.load = TRUE}\\{}\\{}
NULL or FALSE, in which case pagerefs are dynamically calculated for each record. (Default) \\{}
A vector giving sorted byte offsets for each record for mmap reading of data files.\\{}
TRUE, in which case a full page reference table is computed before any processing occurs.\\{}\\{}

Computing pagerefs takes a little time and so is a little slower. However, it is safer than dynamic computations in the case of missing pages and high temperature variations. Further, once page references are calculated, future reads are much faster, so long as the previously computed references are supplied.



\item[\code{...}] Any other optional arguments can be supplied that affect manual calibration and data processing.  These are: \\{}\\{}

\code{gain}: a vector of 3 values for manual gain calibration of the raw (x,y,z) axes.  If \code{gain=NULL}, the gain calibration values are taken from within the output file itself.\\{}

\code{offset}: a vector of 3 value for manual offset calibration of the raw (x,y,z) axes.  If \code{offset=NULL}, the offset calibration values are taken from within the output file itself.\\{}

\code{luxv}: a value for manual lux calibration of the light meter.  If \code{luxv=NULL}, the lux calibration value is taken from within the output file itself.\\{}

\code{voltv}: a value for manual volts calibration of the light meter.  If \code{voltv=NULL}, the volts calibration value is taken from within the output file itself.\\{}

\code{warn}: if set to true, give a warning if input file is large, and require user confirmation.


\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The read.bin package reads in binary files compatible with the GeneActiv line of Accelerometers, for further processing by the other functions in this package. Most of the default options are those required in the most common cases, though users are advised to consider setting start and end to smaller intervals and/or choosing some level of downsampling when working with data files of longer than 24 hours in length.

The function reads in the desired analysis time window specified by \code{start} and \code{end}. For convenience, a variety of time window formats are accepted:

Large integers are read as page numbers in the dataset. Page numbers larger than that which is available in the file itself are constrained to what is available. Note that the first page is page 1.

Small values (between 0 and 1) are taken as proportions of the data. For example, `start = 0.5` would specify that reading should begin at the midpoint of the data.

Strings are interpreted as dates and times using \code{\LinkA{parse.time}{parse.time}}. In particular, times specified as "HH:MM" or "HH:MM:SS" are taken as the earliest time interval containing these times in the file. Strings with an integer prepended, using a space seperator, as interpreted as that time after the appropriate number of midnights have passed - in other words, the appropriate time of day on the Nth *full* day. Days of the week and dates in "day/month", "day/month/year", "month-day", "year-month-day" are also handled. Note that the time is interpreted in the same time zone as the data recording itself.

Actual data reading proceeds by two methods, depending on whether \code{mmap} is true or false. With \code{mmap = FALSE}, data is read in line by line using \code{readLine} until blocksize is filled, and then processed. With \code{mmap = TRUE}, the \code{\LinkA{mmap}{mmap}} package is used to map the entire data file into an address file, byte locations are calculated (depending on the setting of \code{pagerefs}), \code{blocksize} chunks of data are loaded, and then processed as raw vectors. 

There are advantages and disadvantages to both methods: the mmap method is usually much faster, especially when we are only loading the final parts of the data. ReadLine will have to process the entire file in such a case. On the other hand, mmap requires a large amount of memory address space, and so can fail in 32 bit systems. Finally, reading of compressed bin files can only be done with the readLine method. Generally, if mmap reading fails, the function will attempt to catch the failure, and reprocess the file with the readLine method, giving a warning.

Once data is loaded, calibration is then either performed using values from the binary file, or using manually inputted values (using the \code{gain}, \code{offset},\code{luxv} and \code{voltv} arguments).

\end{Details}
%
\begin{Value}
With \code{virtual = FALSE}, an "AccData" S3 object with 9 components:
\begin{ldescription}
\item[\code{data.out}] A 6 or 7 column matrix of the processed pages, the rows of which are the processed observations in order of processed pages.  The matrix has columns (timestamp,x-axis,y-axis,z-axis,light,button) or (timestamp,x-axis,y-axis,z-axis,light,button,temperature) if \code{do.temp=TRUE}. The timestamp is stored as seconds since 1 Jan 1970, in the timezone that the data is recorded in.
\item[\code{page.timestamps}] The timestamps as POSIXct representations (as opposed to those within the \code{data.out} array.)
\item[\code{freq}] The effective sampling frequency (in Hz).
\item[\code{filename}] The file name of the bin file.
\item[\code{page.numbers}] The pages that were loaded.
\item[\code{call}] The function call that the object was created with.
\item[\code{volt}] The battery voltage associated with each loaded page, if \code{do.volt} is TRUE.
\item[\code{pagerefs}] The page byte offsets that were computed.
\item[\code{header}] File header output, as given by \code{\LinkA{header.info}{header.info}}.

\end{ldescription}
Various processing methods are implemented so that \code{AccData} objects can be treated as an ordinary matrix in many cases. See \code{\LinkA{print.AccData}{print.AccData}} for info.

With \code{virtual = TRUE}, a "VirtAccData" S3 object with page.timestamps, freq, filename, page.numbers, call, pagerefs, header as in the earlier case, but also,
\begin{ldescription}
\item[\code{data.out}] A vector containing the timestamps of each page, using local seconds since 1970.
\item[\code{nobs}] Number of observations per page, after downsampling.
\end{ldescription}
\end{Value}
%
\begin{Section}{Warning}
Reading in an entire .bin file will take a long time if the file contains a lot of datasets. Reading in such files without downsampling can use up all available memory. See \code{\LinkA{memory.limit}{memory.limit}}.

This function is specific to header structure in Geneactiv output files. By design, it should be compatible with all firmware and software versions to date (as of version of current release). If order or field names are changed in future .bin files, this function may have to be updated appropriately.
\end{Section}
%
\begin{SeeAlso}\relax
\code{\LinkA{header.info}{header.info}}, \code{\LinkA{print.AccData}{print.AccData}}, \code{\LinkA{get.intervals}{get.intervals}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

binfile  = system.file("binfile/TESTfile.bin", package = "ReadGenea")[1]

#Read in the entire file, calibrated
procfile<-read.bin(binfile)
print(procfile)
procfile$data.out[1:5,]

#Uncalibrated, mmap off
procfile2<-read.bin(binfile, calibrate = FALSE)
procfile2$data.out[1:5,]

#Read in again, reusing already computed mmap pagerefs
procfile3<-read.bin(binfile, pagerefs = procfile2$pagerefs )

#Downsample by a factor of 10
procfilelo<-read.bin(binfile, downsample = 10)
print(procfilelo)
object.size(procfilelo) / object.size(procfile)

#Read in a 1 minute interval
procfileshort <- read.bin(binfile, start = "16:50", end = "16:51")
print(procfileshort)

##NOT RUN: Read, and save as a R workspace
#read.bin(binfile, outfile="tmp.Rdata")
#print(load("tmp.Rdata"))
#print(processedfile)


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{RGtime}{Date time handling for the ReadGenea package.}{RGtime}
\aliasA{as.RGtime}{RGtime}{as.RGtime}
\aliasA{axis.RGtime}{RGtime}{axis.RGtime}
\aliasA{convert.time}{RGtime}{convert.time}
\aliasA{format.RGtime}{RGtime}{format.RGtime}
\aliasA{pretty.RGtime}{RGtime}{pretty.RGtime}
\keyword{manip}{RGtime}
%
\begin{Description}\relax
Stores date time data as a numeric, with facility for pretty printing and axis commands.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
convert.time(x, format = NULL)
as.RGtime(x, format = NULL, ...)
## S3 method for class 'RGtime'
format(x, format = NULL, ...)
## S3 method for class 'RGtime'
axis(side, x=NULL, at=NULL, format = NULL,labels  = TRUE, add = TRUE,  ...)
## S3 method for class 'RGtime'
pretty(x, n = 5, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] Object to process. For \code{convert.time}, must be numeric. For \code{as.RGtime} may be numeric or character. For \code{format.RGtime}, a RGtime object, or a numeric.
\item[\code{format}] A character string indicating the form of output. See \code{\LinkA{strptime}{strptime}} for details. If NULL, will be automatically chosen.
\item[\code{add}] logical. If TRUE, actually plot the axis.
\item[\code{at, side, labels}] Additional arguments as in \code{\LinkA{axis}{axis}}.
\item[\code{n}] Approximate number of breakpoints.
\item[\code{...}] Additional arguments to be passed to \code{\LinkA{parse.time}{parse.time}}, \code{\LinkA{as.numeric}{as.numeric}}, \code{\LinkA{format.POSIXct}{format.POSIXct}}, \code{\LinkA{axis}{axis}}, \code{\LinkA{pretty.POSIXt}{pretty.POSIXt}}. 
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The RGtime class handles dates and times for the ReadGenea class. The class treats dates as numerics denoting seconds since the UNIX epoch, with potentially a string attached specifying the format to print in. Unlike \code{POSIXct}, we avoid some of the processing, especially with respect to time zones, and allow some more flexibility in time computation and display. A range of operators are defined.

\code{convert.time} converts numerics to RGtime objects. The \code{format} argument allows a format string to be attached specifying the default format to display in. \code{as.RGtime} is a wrapper to \code{convert.time}, that when supplied with character input, coerces the value first to numeric using \code{parse.time}.

\code{format.RGtime} formats RGtime objects for pretty printing. If \code{format} is provided as argument, that is used. Else, if the \code{format} attribute is set on \code{x}, that is used. Finally, if formats are not provided, and \code{x} is of length greater than one, the range of values of \code{x} is used to decide the units displayed. Numerics are also accepted - they are coerced to RGtime.

\code{axis.RGtime} is used to plot RGtime axis, choosing, by default, breakpoints that give 'pretty' sub intervals. Note that \code{\LinkA{plot.default}{plot.default}} uses \code{axis.RGtime} by default if supplied with a RGtime object in one of the directions. However, \code{\LinkA{image.default}{image.default}} based functions do not use the class axis functions, so axes must be plotted manually.

\code{pretty.RGtime} computes 'pretty' breakpoints, using the algorithm of \code{pretty.POSIXt}. Attributes are preserved.

\end{Details}
%
\begin{Value}
For \code{convert.time}, \code{as.RGtime} and \code{pretty.RGtime}, a RGtime object.

For \code{format.RGtime} a character string representation.

For \code{axis.RGtime} a list containing positions and labels for axis markers.
\end{Value}
%
\begin{SeeAlso}\relax
\code{\LinkA{parse.time}{parse.time}}, \code{\LinkA{get.intervals}{get.intervals}}, \code{\LinkA{print.AccData}{print.AccData}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
as.RGtime("00:01")
#format is automatically set
convert.time(1:10)
convert.time(1:10*1000)
#we add a different default format
convert.time(1:10*1000, "%H:%M:%OS3") -> t
t
str(t)
#we override format with our own
format(t, format = "%a %d/%m/%y %H:%M:%OS3")

#plot calls axis.RGtime automatically. Notice
#that the format attribute is used.
plot(t, 1:10)
#strip out the default format
t2 = convert.time(t, format = NULL)
plot(t2, 1:10)

#image plots are a bit more complex

Z = matrix(rnorm(100), 10)
image(x = t, y = t2, z = Z, axes = FALSE)
axis.RGtime(x = t2, side = 2)
Axis(x = t, side = 1) #Axis also works
box() #complete the bounding box

#custom axes
plot(t2, 1:10, xaxt = "n")
axis.RGtime(at = pretty(t2, 20) , side = 1)
\end{ExampleCode}
\end{Examples}
\printindex{}
\end{document}
