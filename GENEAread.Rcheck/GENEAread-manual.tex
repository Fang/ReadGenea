\nonstopmode{}
\documentclass[a4paper]{book}
\usepackage[times,inconsolata,hyper]{Rd}
\usepackage{makeidx}
\usepackage[utf8,latin1]{inputenc}
% \usepackage{graphicx} % @USE GRAPHICX@
\makeindex{}
\begin{document}
\chapter*{}
\begin{center}
{\textbf{\huge Package `GENEAread'}}
\par\bigskip{\large \today}
\end{center}
\begin{description}
\raggedright{}
\item[Type]\AsIs{Package}
\item[Title]\AsIs{Package For Reading Binary files}
\item[Version]\AsIs{1.0}
\item[Date]\AsIs{19/06/2012}
\item[Author]\AsIs{Zhou Fang }\email{zhou@activinsights.co.uk}\AsIs{}
\item[Maintainer]\AsIs{ActivInsights Ltd. }\email{joss.langford@activinsights.co.uk}\AsIs{}
\item[Description]\AsIs{Functions and analytics for GENEA-compatible accelerometer data into R objects. See topic 'GENEAread' for an introduction to the package.}
\item[License]\AsIs{GPL}
\item[LazyLoad]\AsIs{yes}
\item[ByteCompile]\AsIs{yes}
\item[Depends]\AsIs{bitops}
\item[Suggests]\AsIs{mmap, MASS}
\end{description}
\Rdcontents{\R{} topics documented:}
\inputencoding{utf8}
\HeaderA{GENEAread-package}{GENEAread: a package to process binary accelerometer output files.}{GENEAread.Rdash.package}
\aliasA{GENEAread}{GENEAread-package}{GENEAread}
\keyword{package}{GENEAread-package}
%
\begin{Description}\relax
This is a package to process binary output files from the GENEA accelerometer data.  The main functions are:\\{}\\{}

read.bin\\{}
stft\\{}
epoch.apply\\{}
\end{Description}
%
\begin{Details}\relax

\Tabular{ll}{
Package: & GENEAread\\{}
Type: & Package\\{}
Version: & 1.0\\{}
Date: & 19/06/2012\\{}
License: & GPL\\{}
LazyLoad: & yes\\{}
}

\end{Details}
%
\begin{Section}{Main tasks performed}
The main tasks performed by the package are listed below. The relevant topic contains documentation and examples for each.
\begin{description}

\item[Extraction of file header material] is accomplished by \code{\LinkA{header.info}{header.info}}.
\item[Input and downsampling of data] is accomplished by \code{\LinkA{read.bin}{read.bin}}.

\item[Selection of time intervals] is accomplished via \code{\LinkA{get.intervals}{get.intervals}}.
\item[Computation of epochal summaries] is accomplished by \code{\LinkA{epoch.apply}{epoch.apply}} and other functions documented therein.
\item[Computation of STFT analyses] is accomplished by \code{\LinkA{stft}{stft}}.

\end{description}

\end{Section}
%
\begin{Section}{Classes implemented}
The package provides definitions and methods for the following S3 classes:
\begin{description}

\item[GRtime:] Provides numeric storage and streamlined plotting for times. \code{\LinkA{GRtime}{GRtime}}
\item[AccData:] Stores GENEA accelerometer data, allowing plotting, subsetting and other computation. \code{\LinkA{AccData}{AccData}}
\item[VirtAccData:] A virtual AccData object, for just-in-time data access via \code{\LinkA{get.intervals}{get.intervals}}.
\item[stft:] Processed STFT outputs, for plotting via \code{\LinkA{plot.stft}{plot.stft}}.

\end{description}

\end{Section}
%
\begin{Author}\relax
Zhou Fang <zhou@activinsights.co.uk>
ActivInsights Ltd. <joss.langford@activinsights.co.uk>
\end{Author}
\inputencoding{utf8}
\HeaderA{AccData}{Methods for processing and summarising AccData.}{AccData}
\aliasA{\$.AccData}{AccData}{.Rdol..AccData}
\aliasA{plot.AccData}{AccData}{plot.AccData}
\aliasA{print.AccData}{AccData}{print.AccData}
\aliasA{summary.AccData}{AccData}{summary.AccData}
\aliasA{[.AccData}{AccData}{[.AccData}
\keyword{methods}{AccData}
%
\begin{Description}\relax
A variety of functions and methods for handling processed AccData.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'AccData'
x[i=1:dim(x$data.out)[1], j=NULL, drop=TRUE]
## S3 method for class 'AccData'
x$name
## S3 method for class 'AccData'
print(x, ...)
## S3 method for class 'AccData'
summary(object, ...)
## S3 method for class 'AccData'
plot(x, y=NULL, what = c("sd", "mean", "temperature", "light", "voltage"),draw = TRUE, resolution = 200,...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x, object}] "AccData" object to process.
\item[\code{i,j}] Coordinates for matrix like manipulation.
\item[\code{drop}] logical. Coerce to vector if one dimensional?
\item[\code{name}] list field to extract.
\item[\code{y}] Optional variable to plot as y-axis.
\item[\code{what}] Type of plot to create.
\item[\code{draw}] logical. Whether to plot output.
\item[\code{resolution}] Approximate number of time steps to plot.
\item[\code{...}] Additional arguments to pass to default methods.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
These functions allow access and manipulation of AccData class objects.

\code{[} allows matrix style manipulations. If the first column (the timestamp column) is included, a data.frame is produced with the timestamp as a "GRtime" object via \code{\LinkA{convert.time}{convert.time}}. This allows improved plotting of time axes. If j is not specified, an "AccData" object is returned.

\code{\$} allow list style manipulations. In addition to the internal components of "AccData" objects (see \code{\LinkA{read.bin}{read.bin}}), a number of keywords are recognised:

"time": Timestamp
"x","y","z": x, y and z accelerometer components
"xyz": The three accelerometer components together
"temperature"
"button"
"voltage"
"light"
"svm": Sum of vector magnitudes

\code{print} and \code{summary} both provide useful summaries of the data. Summary returns invisibly an object representation of its output in list format - in particular, it gives summary statistics of epochal standard deviations on a 10 second epoch.

Finally, plot provides a range of useful summary plots, depending on the specification of \code{what}. To reduce computational requirements, epochs and so on are chosen or downsampling done so that a maximum of around 100 time points are plotted. If \code{plot} is called with a specified \code{y}, \code{x} is considered as its vector of timestamps. If \code{draw = FALSE}, plot produces no side effects but instead returns the object that would have been plotted.
\end{Details}
%
\begin{SeeAlso}\relax
\code{\LinkA{header.info}{header.info}}, \code{\LinkA{epoch.apply}{epoch.apply}}, \code{\LinkA{get.intervals}{get.intervals}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

binfile  = system.file("binfile/TESTfile.bin", package = "GENEAread")[1]

#Read in the entire file, calibrated
procfile<-read.bin(binfile)

print(procfile)
summary(procfile)

plot(procfile$temperature)
plot(procfile[,c(1,7)])

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{epoch.apply}{Compute epochal summary statistics.}{epoch.apply}
\aliasA{epoch.autocor}{epoch.apply}{epoch.autocor}
\aliasA{epoch.mad}{epoch.apply}{epoch.mad}
\aliasA{epoch.mean}{epoch.apply}{epoch.mean}
\aliasA{epoch.median}{epoch.apply}{epoch.median}
\aliasA{epoch.quantile}{epoch.apply}{epoch.quantile}
\aliasA{epoch.sd}{epoch.apply}{epoch.sd}
\aliasA{svm}{epoch.apply}{svm}
\keyword{ts}{epoch.apply}
%
\begin{Description}\relax
Computes epochal summary statistics for an "AccData" object, matrix, or vector, and collates into a matrix or vector.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
epoch.apply(obj, epoch.size=10, incl.date = FALSE, FUN)

epoch.mean(obj, epoch.size=10, incl.date = FALSE, sqrt )
epoch.sd(obj, epoch.size=10, incl.date = FALSE, sqrt )
epoch.median(obj, epoch.size=10, incl.date = FALSE, sqrt )
epoch.mad(obj, epoch.size=10, incl.date = FALSE, sqrt )
epoch.autocor(obj, epoch.size=10, lag = 1, type = 
    c("correlation", "covariance", "partial"), incl.date = FALSE, sqrt)
epoch.quantile(obj, epoch.size = 10, 
    quantiles= c(0.1, 0.25, 0.5, 0.75, 0.9), incl.date = FALSE, sqrt )

svm(obj, sqrt )
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obj}] The object to compute statistics for. Can be an "AccData" object, a matrix, or a vector.
\item[\code{epoch.size}] Numeric giving intervals to consider and aggregate. For "AccData" \code{obj} taken as seconds. Otherwise, considered as rows, or as individual readings.
\item[\code{incl.date}] logical. If TRUE, include a column of times or original indices with the results.
\item[\code{FUN}] A function to be applied to each epoch.
\item[\code{sqrt}] logical. If TRUE, the square rooted svm will be used in computations instead.
\item[\code{lag}] Autocorrelation lag to compute.
\item[\code{type}] Type of autocorrelation, as used in \code{\LinkA{acf}{acf}}.
\item[\code{quantiles}] Sample quantiles of SVM to compute.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
These functions compute epochal summary statistics for "AccData" objects, matrices and vectors.

\code{epoch.apply} is the general function - according to the size of \code{epoch.size}, it splits up the obj into collections of consecutive rows, each with the same size. These are then successively supplied to \code{FUN} as its first argument. If the result of FUN is a single value, then the results are concatenated into a vector output. Otherwise, an array is formed with each row corresponding to a single epochal group. For AccData, the sampling frequency of the dataset is used to interpret the epoch size in seconds. Otherwise, the raw record indices are used. If incl.date is set, the original timestamp vector of the data, or the original indices, are downsampled and included as the first column of the output.

The remaining functions are wrappers that compute various commonly useful statistics -- in particular, applied to "AccData" objects and arrays, they by default compute the epochal SVM mean, standard deviation, median, median absolute deviation, and autocorrelation, and sample quantiles respectively. (Arrays are treated as each column representing the x, y, and z components respectively.) Applied to vector input, processing will occur without the SVM calculation. This behaviour may be overridden by the sqrt setting, which will force the function to use the squared (default for arrays and "AccData") or original unit (default for vectors) values in the statistical analysis.

\code{svm} acts identically to 'epoch.mean', with the epoch set to the sampling period. In other words, it computes the instantaneous sum of vector magnitudes of the acceleration at each record point. The function takes "AccData", array and vector input. Note that if provided with an array with 4 or more columns, columns 2 to 4 are used -- the first column is regard as a timestamp and hence ignored.
\end{Details}
%
\begin{Value}
A vector or array giving the computed epochal summaries. With \code{incl.date = TRUE}, the result is given as a data.frame suitable for plotting.
\end{Value}
%
\begin{SeeAlso}\relax
\code{\LinkA{plot.AccData}{plot.AccData}}, \code{\LinkA{summary.AccData}{summary.AccData}}, \code{\LinkA{aggregate}{aggregate}}, \code{\LinkA{acf}{acf}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

dat <- read.bin(system.file("binfile/TESTfile.bin", package = "GENEAread")[1]
    , calibrate = TRUE)

#look for the epochs that exceed a certain threshold 50% of the time
plot(epoch.apply( dat, epoch.size = 3 , 
    FUN = function(t) mean(abs(svm(t) -1)>0.2)> 0.5 ), type = "l")

plot(dat[,1], svm(dat), log = "y", pch = ".")
lines(epoch.mean(dat, incl.date = TRUE), lwd = 2)
lines(epoch.mean(dat, epoch.size = 30, incl.date = TRUE), col = 2, lwd = 2)
#this should give all the same results, but by a different way
lines(epoch.apply(dat, epoch.size = 30, 
    FUN = function(A) mean(svm(A, FALSE)), incl.date = TRUE), col = 3)
epsize = 30; lines(epoch.apply(dat, epoch.size = epsize, 
    FUN = function(t) median(t[,1])), epoch.apply(dat, epoch.size = epsize, 
    FUN = function(A) mean(svm(A, FALSE))), col = 4)
#note this is different
lines(epoch.apply(dat, epoch.size = epsize, 
    FUN = function(t) median(t[,1])),epoch.apply(dat, epoch.size = epsize, 
    FUN = function(A) mean(svm(A, sqrt = TRUE)))^2, col = 5)

#plot some statistics
par(mfrow = c(5,1), mar = c(1,4.5,1,1))
plot(epoch.sd(dat), type="l")
plot(epoch.median(dat), type= "l")
plot(epoch.mad(dat), type= "l")
plot(epoch.autocor(dat), type= "l")
tmp = epoch.quantile(dat, quantiles= c(0.1, 0.25, 0.5, 0.75, 0.9)); matplot(tmp, type = "l")


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{get.intervals}{Extract an interval of data.}{get.intervals}
\aliasA{print.VirtAccData}{get.intervals}{print.VirtAccData}
\aliasA{VirtAccData}{get.intervals}{VirtAccData}
\keyword{manip}{get.intervals}
%
\begin{Description}\relax
Function for extracting sub intervals of data, and implementation of just-in-time loading.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
get.intervals(x, start=0, end = 1, length = NULL, time.format = c("auto", "seconds", "days", "proportion", "measurements", "time"), incl.date = FALSE, simplify = TRUE ,read.from.file=FALSE, size=Inf, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] Object to process. Can be array, 
\item[\code{start}] Start of interval.
\item[\code{end}] End of interval.
\item[\code{length}] Length of interval.
\item[\code{time.format}] Method with which \code{start} and \code{end} should be understood.
\item[\code{incl.date}] logical. Include a column denoting time?
\item[\code{simplify}] logical. If TRUE, output an array. Otherwise output a AccData object.
\item[\code{read.from.file}] logical. If TRUE, re-read the relevant time interval from the original bin file.
\item[\code{size}] Desired number of samples in output.
\item[\code{...}] Additional arguments to be passed to \code{\LinkA{read.bin}{read.bin}}, if \code{read.from.file} is TRUE.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The function extracts the desired analysis time window specified by \code{start} and \code{end}. If length is specified, then the end is set to a point \code{length} units after start. The times are interpreted in terms of \code{time.format}. For convenience, a variety of time window formats are accepted:

"seconds": Seconds since start of dataset.

"days": Days since start of dataset.

"proportion": Proportional point within dataset, given as a numeric between 0 and 1.

"measurements": Raw number of samples since start of dataset.

"time": Time string, as understood via \code{\LinkA{parse.time}{parse.time}}.

"auto": Default - attempt to determine time format from size and type of \code{start}.

Some capacity for using mixed types of inputs for \code{start} and \code{length} in particular is present.

The input object \code{x} is typically an "AccData" object, though arrays are also accepted. "VirtAccData" are dealt with by using the timestamp and call information recorded within them to do a new read of the original bin file, assuming this is still available. This is useful for 'just in time' reads of data. "AccData" can be dealt with in this way by setting \code{read.from.file}.

Note that for \code{read.from.file}, only "time" and "proportion" \code{time.format} are presently supported.

\end{Details}
%
\begin{Value}
With \code{simplify = FALSE}, an "AccData" S3 object with the desired records.

Otherwise, an array containing either 3 or 4 columns, containing the x, y, z acceleration vectors and optionally a time vector.
\end{Value}
%
\begin{SeeAlso}\relax
\code{\LinkA{read.bin}{read.bin}}, \code{\LinkA{[.AccData}{[.AccData}}, \code{\LinkA{get.intervals}{get.intervals}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

binfile  = system.file("binfile/TESTfile.bin", package = "GENEAread")[1]

#Read in a highly downsampled version of the file
procfile<-read.bin(binfile, downsample = 100)
print(procfile)
#Plot the x component
plot(procfile[,1:2], type = "l")

#Overlay some segments in different colour
lines(get.intervals(procfile, start = 0.4, end = 0.5, time.format = "prop", incl.date = TRUE)[,1:2], col=2) 
lines(get.intervals(procfile, start = 0.4, end = 5, time.format = "sec", incl.date = TRUE)[,1:2], col=3) 
lines(get.intervals(procfile, start = "16:51", end = "16:52", time.format = "time", incl.date = TRUE)[,1:2], col=4) 
#Note that measurements will depend on the downsampling rate, not the original sampling rate of the data
lines(get.intervals(procfile, start = 100, length = 10, time.format = "measurement", incl.date = TRUE)[,1:2], col=5) 
#This is also understood
lines(get.intervals(procfile, start = "16:52:10", 30,  incl.date = TRUE)[,1:2], col=6) 

#Now load in virtually
virtfile<-read.bin(binfile, virtual = TRUE)
#Notice that get.intervals with simplify = FALSE gives a genuine AccData object
realfile = get.intervals(virtfile, start = 0.5, end = 1, simplify = FALSE)
virtfile
realfile
#get.intervals calls read.bin automatically
points(get.intervals(virtfile, start = "16:52:10", "16:52:40",  incl.date = TRUE)[,1:2], col=4, pch = ".") 

#Alternatively, re-read procfile at a different resampling rate.
lines(get.intervals(procfile, start = "16:49:00", "16:49:30",  incl.date = TRUE, read.from.file = TRUE, downsample = 300)[,1:2], col=2) 


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{GRtime}{Date time handling for the GENEAread package.}{GRtime}
\aliasA{as.GRtime}{GRtime}{as.GRtime}
\aliasA{axis.GRtime}{GRtime}{axis.GRtime}
\aliasA{convert.time}{GRtime}{convert.time}
\aliasA{format.GRtime}{GRtime}{format.GRtime}
\aliasA{pretty.GRtime}{GRtime}{pretty.GRtime}
\keyword{methods}{GRtime}
%
\begin{Description}\relax
Stores date time data as a numeric, with facility for pretty printing and axis commands.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
convert.time(x, format = NULL)
as.GRtime(x, format = NULL, ...)
## S3 method for class 'GRtime'
format(x, format = NULL, ...)
## S3 method for class 'GRtime'
axis(side, x=NULL, at=NULL, format = NULL,labels  = TRUE, add = TRUE,  ...)
## S3 method for class 'GRtime'
pretty(x, n = 5, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] Object to process. For \code{convert.time}, must be numeric. For \code{as.GRtime} may be numeric or character. For \code{format.GRtime}, a GRtime object, or a numeric.
\item[\code{format}] A character string indicating the form of output. See \code{\LinkA{strptime}{strptime}} for details. If NULL, will be automatically chosen.
\item[\code{add}] logical. If TRUE, actually plot the axis.
\item[\code{at, side, labels}] Additional arguments as in \code{\LinkA{axis}{axis}}.
\item[\code{n}] Approximate number of breakpoints.
\item[\code{...}] Additional arguments to be passed to \code{\LinkA{parse.time}{parse.time}}, \code{\LinkA{as.numeric}{as.numeric}}, \code{\LinkA{format.POSIXct}{format.POSIXct}}, \code{\LinkA{axis}{axis}}, \code{\LinkA{pretty.POSIXt}{pretty.POSIXt}}. 
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The GRtime class handles dates and times for the GENEAread class. The class treats dates as numerics denoting seconds since the UNIX epoch, with potentially a string attached specifying the format to print in. Unlike \code{POSIXct}, we avoid some of the processing, especially with respect to time zones, and allow some more flexibility in time computation and display. A range of operators are defined.

\code{convert.time} converts numerics to GRtime objects. The \code{format} argument allows a format string to be attached specifying the default format to display in. \code{as.GRtime} is a wrapper to \code{convert.time}, that when supplied with character input, coerces the value first to numeric using \code{parse.time}.

\code{format.GRtime} formats GRtime objects for pretty printing. If \code{format} is provided as argument, that is used. Else, if the \code{format} attribute is set on \code{x}, that is used. Finally, if formats are not provided, and \code{x} is of length greater than one, the range of values of \code{x} is used to decide the units displayed. Numerics are also accepted - they are coerced to GRtime.

\code{axis.GRtime} is used to plot GRtime axis, choosing, by default, breakpoints that give 'pretty' sub intervals. Note that \code{\LinkA{plot.default}{plot.default}} uses \code{axis.GRtime} by default if supplied with a GRtime object in one of the directions. However, \code{\LinkA{image.default}{image.default}} based functions do not use the class axis functions, so axes must be plotted manually.

\code{pretty.GRtime} computes 'pretty' breakpoints, using the algorithm of \code{pretty.POSIXt}. Attributes are preserved.

\end{Details}
%
\begin{Value}
For \code{convert.time}, \code{as.GRtime} and \code{pretty.GRtime}, a GRtime object.

For \code{format.GRtime} a character string representation.

For \code{axis.GRtime} a list containing positions and labels for axis markers.
\end{Value}
%
\begin{SeeAlso}\relax
\code{\LinkA{parse.time}{parse.time}}, \code{\LinkA{get.intervals}{get.intervals}}, \code{\LinkA{print.AccData}{print.AccData}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
as.GRtime("00:01")
#format is automatically set
convert.time(1:10)
convert.time(1:10*1000)
#we add a different default format
convert.time(1:10*1000, "%H:%M:%OS3") -> t
t
str(t)
#we override format with our own
format(t, format = "%a %d/%m/%y %H:%M:%OS3")

#plot calls axis.GRtime automatically. Notice
#that the format attribute is used.
plot(t, 1:10)
#strip out the default format
t2 = convert.time(t, format = NULL)
plot(t2, 1:10)

#image plots are a bit more complex

Z = matrix(rnorm(100), 10)
image(x = t, y = t2, z = Z, axes = FALSE)
axis.GRtime(x = t2, side = 2)
Axis(x = t, side = 1) #Axis also works
box() #complete the bounding box

#custom axes
plot(t2, 1:10, xaxt = "n")
axis.GRtime(at = pretty(t2, 20) , side = 1)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{hanning.window}{Computes the Coefficients of a Hanning or Uniform Window.}{hanning.window}
\aliasA{uniform.window}{hanning.window}{uniform.window}
\keyword{ts}{hanning.window}
%
\begin{Description}\relax
For \code{hanning.window}, the filter coefficients \eqn{w_i}{} of a Hanning window of length 
\code{n} are computed according to the formula
\deqn{w_i = 0.5 - 0.5 \cos\frac{2\pi i}{n-1}}{}

For \code{uniform.window}, a constant value 1 is repeated for the length(n).
\end{Description}
%
\begin{Usage}
\begin{verbatim}
hanning.window(n)
uniform.window(n)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{n}] The length of the window.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A vector containing the filter coefficients.
\end{Value}
%
\begin{Author}\relax
Andreas Weingessel
\end{Author}
%
\begin{References}\relax
For a definition of the Hanning window, see for example\\{}
Alan V. Oppenheim and Roland W. Schafer: "Discrete-Time Signal
Processing", Prentice-Hall, 1989.
\end{References}
%
\begin{SeeAlso}\relax
stft
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
hanning.window(10)

x<-rnorm(500)
y<-stft(x, wtype="hanning.window")
plot(y)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{header.info}{Get header info from GENEA output (.bin) file}{header.info}
\keyword{IO}{header.info}
%
\begin{Description}\relax
Function to extract relevant header fields and values from a file.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
header.info(binfile, more=TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{binfile}] The file from which to extract the header
\item[\code{more}] logical. If TRUE, extract additional data from file useful for calibration and data reading.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The function extracts useful information from a .bin file, such as information about the GENEA device used to produce the output, and characteristics of the subject who wore the device. The function also accepts data that has been compressed in `gzip', `bzip2' or `xz' formats. See \code{file}.
With \code{more} set to TRUE, additional data is extracted, mainly for internal use in \code{read.bin}.
\end{Details}
%
\begin{Value}
A \code{data.frame} with extracted header information, each row a particular header field with its value. 
If \code{more} is TRUE, an attribute "calibration" is attached to the object, consisting of a list with measurement offsets, sampling frequency estimates, start times and time zones, data position offsets, and if mmap is detected, byte locations and increments for mmap reading.
\end{Value}
%
\begin{Section}{Warning}
This function is specific to header structure in GENEActiv output files. By design, it should be compatible with all firmware and software versions to date (as of version of current release). If order or field names are changed in future .bin files, this function may have to be updated appropriately.
The function works by looking for appropriate section headings in the .bin files.
\end{Section}
%
\begin{SeeAlso}\relax
\code{\LinkA{read.bin}{read.bin}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

fileheader <- header.info(system.file("binfile/TESTfile.bin", package = "GENEAread")[1], more = TRUE)
print(fileheader)
attr(fileheader, "calibration")
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{parse.time}{Parses a character time representation to another format. }{parse.time}
\keyword{utilities}{parse.time}
%
\begin{Description}\relax
Converts a character vector in a variety of forms into either the raw second, second classed as POSIXct, or days since Unix epoch.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
parse.time(t="",format=c("seconds", "days", "POSIX"), tzone = 0, 
	start = NULL, startmidnight = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{t}] A character string representation of a date-time expression.
\item[\code{format}] A character string indicating which representation to output.  Can be either \code{seconds}, \code{days} or \code{POSIX}.
\item[\code{tzone}] The time zone the time is given in, expressed as an offset from UTC in hours.
\item[\code{start}] Earliest allowable time stamp in the data, as seconds since Unix epoch.
\item[\code{startmidnight}] Midnight of day '0' in the data, as seconds since Unix epoch.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The function processes character vectors of the form "DATE TIME" -- that is to say, a maximum of two terms separated by a space per value. 

"TIME" is given in 24 hour format, seperated by colons, in "hh:mm", "hh:mm:ss", "hh:mm:ss:ms" or "hh:mm:ss.ms" format. If ommitted, the time is taken to be 00:00:00.000.

"DATE" can be a date representation as "YYYY-MM-DD", "DD/MM/YY" or "DD/MM/YYYY" (noting the use of a colon or backslash seperator to distinguish between the two). Alternatively, with \code{start} and/or \code{startmidnight} supplied, an integer "NN" or string "DOW" corresponding to a day of the week can be used instead. Then, the function will find the first timestamp matching the correct "TIME", that falls NN midnights after \code{startmidnight} and is after \code{start}, or, in the latter case, the first timestamp after the day of \code{start} that matches the appropriate day of the week. If a blank "DATE" is supplied, the function will either use the UNIX epoch, or find the first match, corresponding to the case NN = 0.

Once this is done the time is converted to the required format: \code{POSIX} is the usual R POSIXct format; \code{days} is the julian days since UNIX epoch 1970-1-1; \code{seconds} is the number of seconds (including subseconds) since 1970-1-1. Note that for formats other than POSIX, the output is in the same timezone as \code{tzone}. POSIX stores the time internally as the time in UTC, and applies a format that gives this time local to the user.
\end{Details}
%
\begin{Value}
A converted date-time string in the specified format. In the case of "seconds", or "days", a numeric. For POSIX, a \code{\LinkA{POSIXct}{POSIXct}} object.
\end{Value}
%
\begin{SeeAlso}\relax
\code{\LinkA{convert.time}{convert.time}}, \code{\LinkA{get.intervals}{get.intervals}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

t1 = parse.time("2012-06-21 13:04:01"); print(t1)
parse.time("21/06/12 13:04:01") #gives the same result

parse.time(c("19/07/70", "20/07/70"), format = "days")
#results here will depend on your locale
parse.time(c("19/07/70", "20/07/70"), format = "POSIX", tzone = -4)

#one is the same day, one can only find a match the next day
parse.time("13:05", start = t1) - t1
parse.time("13:00", start = t1) - t1
#asking to wait 1 midnight means both times are considered as 
#times on the same, full day of data
parse.time(c("1 13:05", "1 13:00"), start = t1) - t1
#2012-06-21 is a Thursday, so this is equivalent
parse.time(c("Fri 13:05", "Fri 13:00"), start = t1) - t1
#Longer form days of the week are also understood. Note that 
#the first day does not get matched.
parse.time(c("Thursday 13:05", "Thursday 13:00"), start = t1) - t1

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{plot.stft}{Plots and prints Short Time Fourier Transforms}{plot.stft}
\aliasA{print.stft}{plot.stft}{print.stft}
\keyword{hplot}{plot.stft}
%
\begin{Description}\relax
Processes a dataset, creating an object contained processed time-frequency analyses. These can then be plotted.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'stft'
plot(x, mode = c("decibels", "modulus", "pval"), log = "", showmax = TRUE, median = FALSE, xaxis = TRUE, topthresh, reassign = (!(is.null(x$LGD)) && !("mv" %in% x$type)), ylim, xlim,new = TRUE, zlim.raw,zlim.quantile, cex, col = gray (63:0/63),...)
## S3 method for class 'stft'
print(x, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] "stft" class object to be processed.
\item[\code{mode}] What should be plotted?\\{}\\{}
"decibels": log10 of FFT modulus\\{}
"modulus": Raw FFT modulus\\{}
"pvalue": P-value of each frequence's modulus assuming that window was in fact white noise of equal equal standard deviation
\item[\code{log}] For \code{log = "y"}, use a log scale on the y axis.
\item[\code{showmax}] Vector or logical. Compute and plot the principle frequency components?
\item[\code{median}] logical. If TRUE, smooth the STFT plot in the time direction with a running median.
\item[\code{xaxis}] logical. If TRUE, plot pretty time axes.
\item[\code{topthresh}] For finite values, crop plot for frequencies higher than this value, and show a summary plot up top.
\item[\code{reassign}] logical. Plot reassigned stft, if available?
\item[\code{xlim, ylim}] Parameters controlling axes limits of plot.
\item[\code{new}] logical. If TRUE, make a new plot. Otherwise overlay on to existing plot.
\item[\code{zlim.raw}] Raw values at which to threshold values for computation of heatmap colours.
\item[\code{zlim.quantile}] Quantile values at which to threshold values for computation of heatmap colours.
\item[\code{cex}] Size of points for reassigned STFT plotting.
\item[\code{col}] Vector of colours to be used for plotting.
\item[\code{...}] Additional arguments to be passed to methods.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
STFT objects are created by the \code{\LinkA{stft}{stft}} function. These methods print some useful summary statistics about them, and produce plots.

\code{mode} determines the type of plot. "decibel" and "modulus" work with the raw values, while "pvalue" conducts some degree of normalisation in each time window and so is perhaps more useful for data showing a large variation in sd across different points in time. If the \code{null.calc} was set in the original stft argument, that is used - otherwise, an Exponential distribution is fit to each window, and the pvalues computed from that.

By default, the function uses some empirical quantile based colour thresholds designed to give somewhat reasonable and informative plots. This can be overridden, however, by setting different \code{zlim.raw} or \code{zlim.quantile} results. This can be useful for comparing two different datasets.

Reassigned stft plots are constructed, by default, when they are available, and when the original was not a "mv" stft. Unlike the heatmap used in the usual stft plot, a 2d scatterplot is used instead. This means that if there are few data points, it can be advantageous to set a higher \code{cex} value for larger points and better display.

With Accelerometer data, often the frequencies of interest are concentrated at the lower frequencies. Topthresh crops the frequency display to show only those frequencies. A summary plot is show on the top, to compensate. Choosing a grid of frequencies, this plot draws one line to represent the energies present in the signal at that particular frequency, and higher. Black lines are drawn for frequencies less than 2/3 the \code{topthresh}, red lines for 2/3 - 1 times \code{topthresh}, and blue lines for frequencies higher than \code{topthresh}. Alternative, set \code{log = "y"} to put frequencies on a log scale.
\end{Details}
%
\begin{Value}
These functions are run for their side effects.
\end{Value}
%
\begin{SeeAlso}\relax
\code{\LinkA{stft}{stft}}, \code{\LinkA{image.default}{image.default}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

#Real data
binfile  = system.file("binfile/TESTfile.bin", package = "GENEAread")[1]

#Read in the entire file, calibrated
procfile<-read.bin(binfile)
#Create stft object
obj = stft(procfile, type = "svm", quiet = TRUE)
#Look at it
print(obj)

plot(obj, cex = 5)
plot(obj, showmax = FALSE, cex = 5) #suppress principals

#pval plot
plot(obj, mode = "pval", cex = 5)
#disable reassigned stft
plot(obj, mode = "pval", reassign = FALSE) 
#median smoothing
plot(obj, mode = "pval", reassign = FALSE, median = TRUE) 
#log scale frequency, no top bar
dev.new(); plot(obj, mode = "pval", reassign = FALSE, topthresh = Inf, log = "y") 
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{read.bin}{File processing function for binary files.}{read.bin}
\keyword{IO}{read.bin}
%
\begin{Description}\relax
A function to process binary accelerometer files and convert the information into R objects.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
read.bin(binfile, outfile = NULL, start = NULL, end = NULL, 
    verbose = TRUE, do.temp = TRUE,do.volt = TRUE, calibrate = TRUE, downsample = NULL, blocksize , virtual = FALSE, mmap.load = (.Machine$sizeof.pointer >= 8), pagerefs = TRUE, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{binfile}] 
A filename of a file to process.

\item[\code{outfile}] 
An optional filename specifying where to save the processed data object.

\item[\code{start}] Either:
A representation of when in the file to begin processing, see Details.

\item[\code{end}] Either:
A representation of when in the file to end processing, see Details.

\item[\code{verbose}] 
A boolean variable indicating whether some information should be printed during processing should be printed.

\item[\code{do.temp}] 
A boolean variable indicating whether the temperature signal should be extracted.

\item[\code{do.volt}] 
A boolean variable indicating whether the voltage signal should be extracted.

\item[\code{calibrate}] 
A boolean variable indicating whether the raw accelerometer values and the light variable should be calibrated according to the calibration data in the headers.

\item[\code{downsample}] 
A variable indicating the type of downsampling to apply to the data as it is loaded. Can take values:\\{}\\{}
\code{NULL}: (Default) No downsampling\\{}
Single numeric: Reads every \code{downsample}-th value, starting from the first.\\{}
Length two numeric vector: Reads every \code{downsample[1]}-th value, starting from the \code{downsample[2]}-th.\\{}\\{}

Non-integer, or non-divisor of 300 downsampling factors are allowed, but will lead to imprecise frequency calculations, leap seconds being introduced, and generally potential problems with other methods. Use with care.


\item[\code{blocksize}] 
Integer value giving maximum number of data pages to read in each pass. Defaults to 10000 for larger data files. Sufficiently small sizes will split very large data files to read chunk by chunk, reducing memory requirements for the read.bin function (without affecting the final object), but conversely possibly increasing processing time. Can be set to Inf for no splitting.


\item[\code{virtual}] 
logical. If set TRUE, do not do any actual data reading. Instead construct a VirtualAccData object containing header information to allow use with \code{\LinkA{get.intervals}{get.intervals}}.


\item[\code{mmap.load}] 
logical. If TRUE (Default on 64bit R), use the \code{\LinkA{mmap}{mmap}} package to process the binfile.


\item[\code{pagerefs}] 
A variable that can take two forms, and is considered only for \code{mmap.load = TRUE}\\{}\\{}
NULL or FALSE, in which case pagerefs are dynamically calculated for each record. (Default) \\{}
A vector giving sorted byte offsets for each record for mmap reading of data files.\\{}
TRUE, in which case a full page reference table is computed before any processing occurs.\\{}\\{}

Computing pagerefs takes a little time and so is a little slower. However, it is safer than dynamic computations in the case of missing pages and high temperature variations. Further, once page references are calculated, future reads are much faster, so long as the previously computed references are supplied.



\item[\code{...}] Any other optional arguments can be supplied that affect manual calibration and data processing.  These are: \\{}\\{}

\code{gain}: a vector of 3 values for manual gain calibration of the raw (x,y,z) axes.  If \code{gain=NULL}, the gain calibration values are taken from within the output file itself.\\{}

\code{offset}: a vector of 3 value for manual offset calibration of the raw (x,y,z) axes.  If \code{offset=NULL}, the offset calibration values are taken from within the output file itself.\\{}

\code{luxv}: a value for manual lux calibration of the light meter.  If \code{luxv=NULL}, the lux calibration value is taken from within the output file itself.\\{}

\code{voltv}: a value for manual volts calibration of the light meter.  If \code{voltv=NULL}, the volts calibration value is taken from within the output file itself.\\{}

\code{warn}: if set to true, give a warning if input file is large, and require user confirmation.


\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The read.bin package reads in binary files compatible with the GeneActiv line of Accelerometers, for further processing by the other functions in this package. Most of the default options are those required in the most common cases, though users are advised to consider setting start and end to smaller intervals and/or choosing some level of downsampling when working with data files of longer than 24 hours in length.

The function reads in the desired analysis time window specified by \code{start} and \code{end}. For convenience, a variety of time window formats are accepted:

Large integers are read as page numbers in the dataset. Page numbers larger than that which is available in the file itself are constrained to what is available. Note that the first page is page 1.

Small values (between 0 and 1) are taken as proportions of the data. For example, `start = 0.5` would specify that reading should begin at the midpoint of the data.

Strings are interpreted as dates and times using \code{\LinkA{parse.time}{parse.time}}. In particular, times specified as "HH:MM" or "HH:MM:SS" are taken as the earliest time interval containing these times in the file. Strings with an integer prepended, using a space seperator, as interpreted as that time after the appropriate number of midnights have passed - in other words, the appropriate time of day on the Nth *full* day. Days of the week and dates in "day/month", "day/month/year", "month-day", "year-month-day" are also handled. Note that the time is interpreted in the same time zone as the data recording itself.

Actual data reading proceeds by two methods, depending on whether \code{mmap} is true or false. With \code{mmap = FALSE}, data is read in line by line using \code{readLine} until blocksize is filled, and then processed. With \code{mmap = TRUE}, the \code{\LinkA{mmap}{mmap}} package is used to map the entire data file into an address file, byte locations are calculated (depending on the setting of \code{pagerefs}), \code{blocksize} chunks of data are loaded, and then processed as raw vectors. 

There are advantages and disadvantages to both methods: the mmap method is usually much faster, especially when we are only loading the final parts of the data. ReadLine will have to process the entire file in such a case. On the other hand, mmap requires a large amount of memory address space, and so can fail in 32 bit systems. Finally, reading of compressed bin files can only be done with the readLine method. Generally, if mmap reading fails, the function will attempt to catch the failure, and reprocess the file with the readLine method, giving a warning.

Once data is loaded, calibration is then either performed using values from the binary file, or using manually inputted values (using the \code{gain}, \code{offset},\code{luxv} and \code{voltv} arguments).

\end{Details}
%
\begin{Value}
With \code{virtual = FALSE}, an "AccData" S3 object with 9 components:
\begin{ldescription}
\item[\code{data.out}] A 6 or 7 column matrix of the processed pages, the rows of which are the processed observations in order of processed pages.  The matrix has columns (timestamp,x-axis,y-axis,z-axis,light,button) or (timestamp,x-axis,y-axis,z-axis,light,button,temperature) if \code{do.temp=TRUE}. The timestamp is stored as seconds since 1 Jan 1970, in the timezone that the data is recorded in.
\item[\code{page.timestamps}] The timestamps as POSIXct representations (as opposed to those within the \code{data.out} array.)
\item[\code{freq}] The effective sampling frequency (in Hz).
\item[\code{filename}] The file name of the bin file.
\item[\code{page.numbers}] The pages that were loaded.
\item[\code{call}] The function call that the object was created with.
\item[\code{page.volts}] The battery voltage associated with each loaded page, if \code{do.volt} is TRUE.
\item[\code{pagerefs}] The page byte offsets that were computed.
\item[\code{header}] File header output, as given by \code{\LinkA{header.info}{header.info}}.

\end{ldescription}
Various processing methods are implemented so that \code{AccData} objects can be treated as an ordinary matrix in many cases. See \code{\LinkA{print.AccData}{print.AccData}} for info.

With \code{virtual = TRUE}, a "VirtAccData" S3 object with page.timestamps, freq, filename, page.numbers, call, pagerefs, header as in the earlier case, but also,
\begin{ldescription}
\item[\code{data.out}] A vector containing the timestamps of each page, using local seconds since 1970.
\item[\code{nobs}] Number of observations per page, after downsampling.
\end{ldescription}
\end{Value}
%
\begin{Section}{Warning}
Reading in an entire .bin file will take a long time if the file contains a lot of datasets. Reading in such files without downsampling can use up all available memory. See \code{\LinkA{memory.limit}{memory.limit}}.

This function is specific to header structure in GENEActiv output files. By design, it should be compatible with all firmware and software versions to date (as of version of current release). If order or field names are changed in future .bin files, this function may have to be updated appropriately.
\end{Section}
%
\begin{SeeAlso}\relax
\code{\LinkA{header.info}{header.info}}, \code{\LinkA{print.AccData}{print.AccData}}, \code{\LinkA{get.intervals}{get.intervals}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

binfile  = system.file("binfile/TESTfile.bin", package = "GENEAread")[1]

#Read in the entire file, calibrated
procfile<-read.bin(binfile)
print(procfile)
procfile$data.out[1:5,]

#Uncalibrated, mmap off
procfile2<-read.bin(binfile, calibrate = FALSE)
procfile2$data.out[1:5,]

#Read in again, reusing already computed mmap pagerefs
procfile3<-read.bin(binfile, pagerefs = procfile2$pagerefs )

#Downsample by a factor of 10
procfilelo<-read.bin(binfile, downsample = 10)
print(procfilelo)
object.size(procfilelo) / object.size(procfile)

#Read in a 1 minute interval
procfileshort <- read.bin(binfile, start = "16:50", end = "16:51")
print(procfileshort)

##NOT RUN: Read, and save as a R workspace
#read.bin(binfile, outfile="tmp.Rdata")
#print(load("tmp.Rdata"))
#print(processedfile)


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{stft}{Computes Short Time Fourier Transforms}{stft}
\keyword{ts}{stft}
%
\begin{Description}\relax
Processes a dataset, creating an object contained processed time-frequency analyses. These can then be plotted.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
stft(X, start=0, end=1, length=NULL,  time.format = c("auto"), 
    type = c("mv", "svm", "sum"), mv.indices, date.col, 
    reassign = TRUE,plot.it = FALSE,...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X}] The dataset to be processed.
\item[\code{start, end, length, time.format}] A specification for the segment to process, as in \code{\LinkA{get.intervals}{get.intervals}}.
\item[\code{type}] The type of STFT to compute.
\item[\code{mv.indices}] For \code{type = "mv"} or \code{type = "sum"}, the indices to process and the order to process them in.
\item[\code{date.col}] logical. Whether the first column should be ignored and treated as a timestamp. If unset, is automatically chosen.
\item[\code{reassign}] logical. If TRUE, compute the time-reassigned STFT. For \code{type \%in\% c("mv", "sum")}, this is done with the first coordinate in \code{mv.indices}.
\item[\code{plot.it}] logical. Whether to plot the STFT immediately when processing is complete, using the default \code{plot.stft} options.
\item[\code{...}] Additional optional arguments to control the STFT computation. These are: \\{}\\{}

\code{win}: Window size in seconds for STFT computation. Increased window size mean better frequency resolution, but poorer time resolution. Defaults to 10 seconds.\\{}

\code{inc}: Increment between successive time steps for processing. Defaults to \code{win/2}. \\{}

\code{coef}: Number of fourier frequencies to compute. Small values will remove the higher frequencies from the processed object. Defaults to the maximum, \code{win/2}.\\{}

\code{wtype}: String giving the name of a window function, providing coefficients for filtering before processing. "hanning.window" is the default, with "uniform.window" also available.\\{}

\code{freq}: Sampling frequency of data set. If not given, is taken from X itself, or assumed to be 1 if unavailable.\\{}

\code{center}: If TRUE (Default), center the data in each window before processing is done. Useful for avoiding excessively large DC offset coefficients in results.\\{}

\code{calc.null}: If TRUE (Defaults to FALSE), compute a 'null' STFT by resampling the data completely, then doing a STFT.\\{}

\code{pvalues}: If TRUE (Defaults to FALSE) Compute bootstrapped pvalues for each position by resampling within each window and applying a wilcox test.\\{}

\code{time}: Allows the user to set an overriding timestamp vector to be used for processing.\\{}

\code{quiet}: If TRUE, suppress output.

\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This function accepts input in a variety of forms and computes short time fourier transforms to extract frequency structure from the data.

X may be an array, a vector, or an AccData object. If date.col is TRUE, the first column of an array X would be used to determine timestamps. Otherwise indices would be used. If date.col is not set, the function will attempt to determine whether the first column is timestamp-like. The timestamp column is removed from X (and so not included in consideration of \code{mv.indices}, for instance).

With vectors, the basic method is to compute the STFT by creating windows of size \code{win} seconds every \code{inc} seconds, and computing the fourier transform. With multi-dimensional data and AccData, processing is done on the dimensions that are in \code{mv.indices}, or the first three non-date columns if that is unavailable. Three methods are possible:

1. \code{type = "mv"}: The one dimensional method is first applied to each of the chosen column indices. These are then collated by choosing, for each time-frequency combination, the maximum such value across each of the indices.

2. \code{type = "svm"}: The SVM is computed first for each time step by computing the square rooted sum of squares. This is then dealt with using the one dimensional method.

3. \code{type = "sum"}: As in "mv", the 1d method is applied. The square of the modulus of the result is then summed and square rooted.

If \code{reassign} is set, the time reassigned stft is also computed for the first element of \code{mv.indices} or the svm as appropriate, by using finite differencing. This gives potentially better resolution results for data with a clear signal component.
\end{Details}
%
\begin{Value}
A "stft" class object - a list with the following components:
\begin{ldescription}
\item[\code{call}] The function call.
\item[\code{type}] Type of STFT computed.
\item[\code{values}] Mod of FFT computed, with each row corresponding to a specific time increment.
\item[\code{increment, windowsize, center, sampling.frequency}] Various control parameters used in the computation.
\item[\code{null.logmean, null.logsd}] Log of the square rooted mean and standard deviation of the Mod FFT squared for the randomised data, if \code{calc.null = TRUE}.
\item[\code{p.values}] Wilcoxian pvalues, if \code{pvalues = TRUE}.
\item[\code{principals}] Principal frequencies.
\item[\code{frequency}] Frequencies at which FFT is computed.
\item[\code{time}] Timestamps for FFT windows.
\item[\code{LGD}] Local group delay matrix for reassigned STFT.
\item[\code{CIF}] Channelized instantaneous frequency matrix for reassigned STFT.
\end{ldescription}
\end{Value}
%
\begin{Section}{Acknowledgements}
The initial implementation of this function is based on that in package \code{e1071}. The reassigned STFT implementation is due to Nelson (2001), via Fulop (2006).
\end{Section}
%
\begin{References}\relax
Fulop, S.A. \& Fitz, K. (2006). Algorithms for computing the time-corrected instantaneous frequency (reassigned) spectrogram, with applications \emph{J Acoustical Society of America} \bold{119(1)}, 360--371.

Nelson. D.J. (2001). Cross-spectral methods for processing speech \emph{J Acoustical Society of America} \bold{110(1)}, 2575-2592.
\end{References}
%
\begin{SeeAlso}\relax
\code{\LinkA{plot.stft}{plot.stft}}, \code{\LinkA{get.intervals}{get.intervals}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
#Some artificial data
time = 1:5000
#sum of two sine curves at 0.3 Hz and 0.05 Hz
f1 = 0.3; f2 = 0.05
sin1 = sin(time * f1 * 2*pi)
sin2 = sin(time * f2 * 2*pi)
#add a bit of noise
signal = sin1 + sin2 + 1*rnorm(5000)
#non-reassigned
stft(signal, plot = TRUE, reassign = FALSE, win = 100)
#reassigned
stft(signal, plot = TRUE, reassign = TRUE, win = 100)

#add a third component: varying frequency.
stft(signal + sin( cumsum(seq(f2, f1, length = 5000))*2*pi), plot = TRUE, reassign = TRUE, win = 100)

#Real data
binfile  = system.file("binfile/TESTfile.bin", package = "GENEAread")[1]

#Read in the entire file, calibrated
procfile<-read.bin(binfile)
#Default is mv
stft(procfile, plot.it = TRUE)
#Try sum?
stft(procfile, plot.it = TRUE, type = "sum", reassign = FALSE)

#Just look at the last 50% of the data
stft(procfile, start = 0.5, plot.it = TRUE)

#not reassigned, svm
stft(procfile, type = "svm", reassign = FALSE, plot.it = TRUE)
#a narrower 5 second window means better time resolution
stft(procfile, type = "svm", reassign = FALSE, plot.it = TRUE, win = 5)
#choose increments so as not to overlap
stft(procfile, type = "svm", reassign = FALSE, plot.it = TRUE, win = 5, inc = 5)
#uniform windows
stft(procfile, type = "svm", reassign = FALSE, plot.it = TRUE, wtype = "uniform.window")

#Svm, reassigned, quietly
obj = stft(procfile, type = "svm", quiet = TRUE)
plot(obj, cex = 3, showmax = FALSE, mode = "pval")
\end{ExampleCode}
\end{Examples}
\printindex{}
\end{document}
